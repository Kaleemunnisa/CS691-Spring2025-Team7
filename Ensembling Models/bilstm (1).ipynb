{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 11439336,
          "sourceType": "datasetVersion",
          "datasetId": 7165760
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. CONFIG\n",
        "Define paths, model filenames, and all hyper‑parameters in one place:\n",
        "- Data path, output weight file  \n",
        "- Embedding/LSTM dimensions, layers, bidirectionality, dropout  \n",
        "- Training settings (max length, batch size, epochs, learning rate)  \n",
        "- Vocabulary minimum frequency & random seed  \n"
      ],
      "metadata": {
        "id": "cAfhnCSNQsgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. CONFIG\n",
        "DATA_PATH      = \"/content/processed_sentiment_data.csv\"\n",
        "MODEL_WEIGHTS  = \"./bilstm_sentiment.pt\"\n",
        "EMBED_DIM      = 128\n",
        "HIDDEN_DIM     = 256\n",
        "N_LAYERS       = 2\n",
        "BIDIRECTIONAL  = True\n",
        "DROPOUT        = 0.3\n",
        "MAX_LEN        = 128\n",
        "BATCH_SIZE     = 64\n",
        "EPOCHS         = 6\n",
        "LR             = 3e-4\n",
        "MIN_FREQ       = 2\n",
        "SEED           = 42\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T04:07:02.024768Z",
          "iopub.execute_input": "2025-04-17T04:07:02.025036Z",
          "iopub.status.idle": "2025-04-17T04:07:02.030108Z",
          "shell.execute_reply.started": "2025-04-17T04:07:02.025017Z",
          "shell.execute_reply": "2025-04-17T04:07:02.029180Z"
        },
        "id": "6Qi1dtjYQsga"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. IMPORTS & REPRODUCIBILITY\n",
        "- Standard libs (regex, random, time, warnings)  \n",
        "- NumPy, pandas for data handling  \n",
        "- PyTorch APIs for model, training, device  \n",
        "- sklearn metrics, DataLoader for batching  \n",
        "- Set global seeds and deterministic behavior  \n"
      ],
      "metadata": {
        "id": "_pdy-O5LQsgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. IMPORTS & REPRODUCIBILITY\n",
        "import re, random, time, collections, warnings, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T04:07:02.031334Z",
          "iopub.execute_input": "2025-04-17T04:07:02.031587Z",
          "iopub.status.idle": "2025-04-17T04:07:02.045711Z",
          "shell.execute_reply.started": "2025-04-17T04:07:02.031569Z",
          "shell.execute_reply": "2025-04-17T04:07:02.044885Z"
        },
        "id": "MVobb-whQsgh"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. TOKENIZER & VOCAB\n",
        "- Simple regex‑based tokenizer  \n",
        "- `Vocab` class to build token ↔ index maps, keeping only words ≥ `MIN_FREQ`  \n",
        "- Special tokens `<pad>` and `<unk>`  \n"
      ],
      "metadata": {
        "id": "kd-f9tJsQsgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. TOKENIZER & VOCAB\n",
        "_token_re = re.compile(r\"\\w+|[^\\w\\s]\", re.UNICODE)\n",
        "\n",
        "def tokenize(text: str):\n",
        "    return _token_re.findall(text.lower())\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, counter, min_freq=1, specials=None):\n",
        "        specials = specials or []\n",
        "        # include specials first, then tokens ≥ min_freq\n",
        "        self.itos = specials + [\n",
        "            w for w, c in counter.items()\n",
        "            if c >= min_freq and w not in specials\n",
        "        ]\n",
        "        self.stoi = {w: i for i, w in enumerate(self.itos)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    def __getitem__(self, token):\n",
        "        # return index or <unk>\n",
        "        return self.stoi.get(token, self.stoi[\"<unk>\"])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T04:07:02.046593Z",
          "iopub.execute_input": "2025-04-17T04:07:02.047130Z",
          "iopub.status.idle": "2025-04-17T04:07:02.058851Z",
          "shell.execute_reply.started": "2025-04-17T04:07:02.047114Z",
          "shell.execute_reply": "2025-04-17T04:07:02.058214Z"
        },
        "id": "4BHV-Dc9Qsgj"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. DATASET\n",
        "- `SentimentDS` wraps a DataFrame of `text` & `sentiment`  \n",
        "- Builds its own vocab on `build_vocab=True`  \n",
        "- Encodes text → list of token‑IDs, truncated to `MAX_LEN`  \n",
        "- Maps sentiment strings → integer labels  \n"
      ],
      "metadata": {
        "id": "h9Fm4bVrQsgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. DATASET\n",
        "class SentimentDS(Dataset):\n",
        "    def __init__(self, df, vocab=None, build_vocab=False):\n",
        "        self.texts = df[\"text\"].fillna(\"\").tolist()\n",
        "        self.orig_labels = df[\"sentiment\"].tolist()\n",
        "\n",
        "        # label mappings\n",
        "        self.label2id = {\n",
        "            l: i for i, l in enumerate(sorted(set(self.orig_labels)))\n",
        "        }\n",
        "        self.id2label = {i: l for l, i in self.label2id.items()}\n",
        "        self.labels = [self.label2id[l] for l in self.orig_labels]\n",
        "\n",
        "        # build or reuse vocab\n",
        "        if build_vocab:\n",
        "            counter = collections.Counter()\n",
        "            for t in self.texts:\n",
        "                counter.update(tokenize(t))\n",
        "            self.vocab = Vocab(counter, MIN_FREQ, specials=[\"<pad>\", \"<unk>\"])\n",
        "        else:\n",
        "            self.vocab = vocab\n",
        "\n",
        "    def encode(self, text):\n",
        "        ids = [self.vocab[t] for t in tokenize(text)[:MAX_LEN]]\n",
        "        if not ids:  # protect against blank text\n",
        "            ids = [self.vocab[\"<unk>\"]]\n",
        "        return ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = torch.tensor(self.encode(self.texts[idx]), dtype=torch.long)\n",
        "        label = self.labels[idx]\n",
        "        return seq, label\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T04:07:02.059710Z",
          "iopub.execute_input": "2025-04-17T04:07:02.059965Z",
          "iopub.status.idle": "2025-04-17T04:07:02.071006Z",
          "shell.execute_reply.started": "2025-04-17T04:07:02.059940Z",
          "shell.execute_reply": "2025-04-17T04:07:02.070230Z"
        },
        "id": "A98jpeexQsgk"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. DATA PREPARATION\n",
        "- Read full CSV, split into train/val (80/20)  \n",
        "- Build vocab on training set  \n",
        "- Create PyTorch `DataLoader` with padding collate fn  \n"
      ],
      "metadata": {
        "id": "odXiV04kQsgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. DATA PREPARATION\n",
        "df_all   = pd.read_csv(DATA_PATH)\n",
        "df_train = df_all.sample(frac=0.8, random_state=SEED)\n",
        "df_val   = df_all.drop(df_train.index)\n",
        "\n",
        "# datasets\n",
        "train_ds = SentimentDS(df_train, build_vocab=True)\n",
        "VOCAB    = train_ds.vocab\n",
        "val_ds   = SentimentDS(df_val, vocab=VOCAB)\n",
        "\n",
        "PAD_IDX   = VOCAB[\"<pad>\"]\n",
        "N_CLASSES = len(train_ds.label2id)\n",
        "\n",
        "# collate_fn for padding & lengths\n",
        "def collate(batch):\n",
        "    seqs, labels = zip(*batch)\n",
        "    lengths = torch.tensor([len(s) for s in seqs], device=DEVICE)\n",
        "    padded  = nn.utils.rnn.pad_sequence(\n",
        "        seqs, batch_first=True, padding_value=PAD_IDX\n",
        "    )\n",
        "    return padded.to(DEVICE), lengths, torch.tensor(labels, device=DEVICE)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds, BATCH_SIZE, shuffle=True, collate_fn=collate\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds, BATCH_SIZE, shuffle=False, collate_fn=collate\n",
        ")\n",
        "\n",
        "print(f\"Vocabulary size: {len(VOCAB)}    Classes: {N_CLASSES}\", file=sys.stderr)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T04:07:02.072388Z",
          "iopub.execute_input": "2025-04-17T04:07:02.072620Z",
          "iopub.status.idle": "2025-04-17T04:07:02.201687Z",
          "shell.execute_reply.started": "2025-04-17T04:07:02.072606Z",
          "shell.execute_reply": "2025-04-17T04:07:02.200960Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSVwtiIRQsgm",
        "outputId": "a5208c32-e21f-44ef-9291-0aa38ee1caa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Vocabulary size: 4330    Classes: 3\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. MODEL\n",
        "- `BiLSTMClassifier` with embedding, packed LSTM, dropout, and final linear layer  \n",
        "- Supports bidirectional LSTM and variable number of layers  \n"
      ],
      "metadata": {
        "id": "LJafs9A5Qsgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. MODEL\n",
        "class BiLSTMClassifier(nn.Module):\n",
        "    def __init__(\n",
        "        self, vocab_size, embed_dim, hidden_dim, n_layers,\n",
        "        n_classes, bidir=True, dropout=0.3, pad_idx=0\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(\n",
        "            vocab_size, embed_dim, padding_idx=pad_idx\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            embed_dim, hidden_dim, n_layers,\n",
        "            batch_first=True, bidirectional=bidir,\n",
        "            dropout=dropout if n_layers > 1 else 0.0\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(\n",
        "            hidden_dim * (2 if bidir else 1), n_classes\n",
        "        )\n",
        "        self.bidir = bidir\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        emb = self.dropout(self.embedding(x))\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        _, (h, _) = self.lstm(packed)\n",
        "        # concat last hidden states from both directions if bidir\n",
        "        if self.bidir:\n",
        "            h = torch.cat((h[-2], h[-1]), dim=1)\n",
        "        else:\n",
        "            h = h[-1]\n",
        "        return self.fc(self.dropout(h))\n",
        "\n",
        "# instantiate, loss & optimizer\n",
        "model = BiLSTMClassifier(\n",
        "    len(VOCAB), EMBED_DIM, HIDDEN_DIM,\n",
        "    N_LAYERS, N_CLASSES, BIDIRECTIONAL,\n",
        "    DROPOUT, PAD_IDX\n",
        ").to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T04:07:02.202470Z",
          "iopub.execute_input": "2025-04-17T04:07:02.202713Z",
          "iopub.status.idle": "2025-04-17T04:07:02.247320Z",
          "shell.execute_reply.started": "2025-04-17T04:07:02.202687Z",
          "shell.execute_reply": "2025-04-17T04:07:02.246778Z"
        },
        "id": "tBoW6g8KQsgp"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. TRAIN / EVAL FUNCTIONS\n",
        "- `run_epoch` handles one pass (train or eval):  \n",
        "  - loops batches, computes loss  \n",
        "  - backprop + step if training  \n",
        "  - collects preds & ground truths  \n",
        "  - returns avg loss & accuracy  \n"
      ],
      "metadata": {
        "id": "GuSSPlOrQsgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. TRAIN / EVAL FUNCTIONS\n",
        "def run_epoch(loader, train=True):\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    total_loss, preds, gts = 0.0, [], []\n",
        "    for x, lengths, y in loader:\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "        logits = model(x, lengths)\n",
        "        loss   = criterion(logits, y)\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        total_loss += loss.item() * y.size(0)\n",
        "        preds.extend(logits.argmax(1).tolist())\n",
        "        gts.extend(y.tolist())\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    acc = accuracy_score(gts, preds)\n",
        "    return avg_loss, acc, preds, gts\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T04:07:02.248743Z",
          "iopub.execute_input": "2025-04-17T04:07:02.248958Z",
          "iopub.status.idle": "2025-04-17T04:07:02.254263Z",
          "shell.execute_reply.started": "2025-04-17T04:07:02.248943Z",
          "shell.execute_reply": "2025-04-17T04:07:02.253645Z"
        },
        "id": "oyn_oPKPQsgq"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. TRAINING LOOP\n",
        "- Loop over epochs, track train/val loss & acc  \n",
        "- Save best model weights when validation accuracy improves  \n"
      ],
      "metadata": {
        "id": "wcw5YCWnQsgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. TRAINING LOOP\n",
        "metrics = []\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    start = time.time()\n",
        "    train_loss, train_acc, _, _ = run_epoch(train_loader, train=True)\n",
        "    val_loss, val_acc, _, _     = run_epoch(val_loader, train=False)\n",
        "    metrics.append({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_loss\": round(train_loss, 4),\n",
        "        \"val_loss\":   round(val_loss,   4),\n",
        "        \"val_acc\":    round(val_acc,    3)\n",
        "    })\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d}/{EPOCHS}  \"\n",
        "        f\"train_loss {train_loss:.4f}  val_loss {val_loss:.4f}  \"\n",
        "        f\"val_acc {val_acc:.3f}  time {time.time()-start:.1f}s\",\n",
        "        file=sys.stderr\n",
        "    )\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), MODEL_WEIGHTS)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T04:07:02.255022Z",
          "iopub.execute_input": "2025-04-17T04:07:02.255778Z",
          "iopub.status.idle": "2025-04-17T04:07:06.156443Z",
          "shell.execute_reply.started": "2025-04-17T04:07:02.255720Z",
          "shell.execute_reply": "2025-04-17T04:07:06.155484Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJitCSArQsgs",
        "outputId": "3a5d2d87-6ac5-482c-808b-0900dd2f23e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 01/6  train_loss 0.9429  val_loss 0.6570  val_acc 0.848  time 1.6s\n",
            "Epoch 02/6  train_loss 0.5873  val_loss 0.4700  val_acc 0.848  time 0.6s\n",
            "Epoch 03/6  train_loss 0.5200  val_loss 0.4712  val_acc 0.848  time 0.6s\n",
            "Epoch 04/6  train_loss 0.5114  val_loss 0.4479  val_acc 0.848  time 0.6s\n",
            "Epoch 05/6  train_loss 0.4925  val_loss 0.4402  val_acc 0.891  time 0.6s\n",
            "Epoch 06/6  train_loss 0.4750  val_loss 0.4331  val_acc 0.891  time 0.6s\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. EPOCH METRICS TABLE\n",
        "Display per‑epoch losses & validation accuracy as a pandas table.\n"
      ],
      "metadata": {
        "id": "zorpgSS3Qsgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. EPOCH METRICS TABLE\n",
        "print(\"\\nEpoch metrics\")\n",
        "print(pd.DataFrame(metrics).to_string(index=False))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T04:07:06.157493Z",
          "iopub.execute_input": "2025-04-17T04:07:06.158030Z",
          "iopub.status.idle": "2025-04-17T04:07:06.164610Z",
          "shell.execute_reply.started": "2025-04-17T04:07:06.158003Z",
          "shell.execute_reply": "2025-04-17T04:07:06.164036Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PesShtS6Qsgt",
        "outputId": "3876183a-1370-4816-f08b-a5ef73fc4688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch metrics\n",
            " epoch  train_loss  val_loss  val_acc\n",
            "     1      0.9429    0.6570    0.848\n",
            "     2      0.5873    0.4700    0.848\n",
            "     3      0.5200    0.4712    0.848\n",
            "     4      0.5114    0.4479    0.848\n",
            "     5      0.4925    0.4402    0.891\n",
            "     6      0.4750    0.4331    0.891\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. CLASSIFICATION REPORT\n",
        "- Load the best saved weights  \n",
        "- Run one final evaluation on validation set  \n",
        "- Print sklearn’s classification report + best val accuracy\n"
      ],
      "metadata": {
        "id": "HIbYXP_xQsgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. CLASSIFICATION REPORT\n",
        "\n",
        "try:\n",
        "    model.load_state_dict(torch.load(MODEL_WEIGHTS, weights_only=True))\n",
        "except TypeError:\n",
        "    model.load_state_dict(torch.load(MODEL_WEIGHTS))\n",
        "\n",
        "# get predictions\n",
        "_, _, y_pred, y_true = run_epoch(val_loader, train=False)\n",
        "print(\"\\nClassification report\")\n",
        "print(classification_report(\n",
        "    y_true, y_pred,\n",
        "    target_names=[train_ds.id2label[i] for i in range(N_CLASSES)],\n",
        "    zero_division=0\n",
        "))\n",
        "print(f\"\\nBest validation accuracy: {best_acc:.3f}\")\n",
        "print(f\"Model weights saved to {MODEL_WEIGHTS}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T04:07:06.165459Z",
          "iopub.execute_input": "2025-04-17T04:07:06.165950Z",
          "iopub.status.idle": "2025-04-17T04:07:06.282208Z",
          "shell.execute_reply.started": "2025-04-17T04:07:06.165919Z",
          "shell.execute_reply": "2025-04-17T04:07:06.281450Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO2PSgX8Qsgu",
        "outputId": "40df5c3c-09c9-4bee-f965-c081dde40454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     LABEL_0       0.89      1.00      0.94       140\n",
            "     LABEL_1       1.00      0.41      0.58        17\n",
            "     LABEL_2       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.89       165\n",
            "   macro avg       0.63      0.47      0.51       165\n",
            "weighted avg       0.85      0.89      0.86       165\n",
            "\n",
            "\n",
            "Best validation accuracy: 0.891\n",
            "Model weights saved to ./bilstm_sentiment.pt\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. INFERENCE FUNCTIONS\n",
        "- `predict(text)` tokenizes & runs the model to return label + confidence  \n",
        "- `demo(lines)` prints a few example inferences  \n"
      ],
      "metadata": {
        "id": "cbY6GGqyQsgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. INFERENCE FUNCTIONS\n",
        "def predict(text):\n",
        "    ids = [VOCAB[t] for t in tokenize(text)[:MAX_LEN]] or [VOCAB[\"<unk>\"]]\n",
        "    tensor = torch.tensor(ids, device=DEVICE).unsqueeze(0)\n",
        "    length = torch.tensor([len(ids)], device=DEVICE)\n",
        "    with torch.no_grad():\n",
        "        logits = model(tensor, length)\n",
        "    idx  = logits.argmax(1).item()\n",
        "    conf = torch.softmax(logits, 1).max().item()\n",
        "    return train_ds.id2label[idx], conf\n",
        "\n",
        "def demo(lines):\n",
        "    print(\"\\nInference examples\")\n",
        "    for s in lines:\n",
        "        label, conf = predict(s)\n",
        "        print(f\"'{s}' -> {label}  ({conf:.2%})\")\n",
        "\n",
        "# run demo\n",
        "demo([\n",
        "    \"I absolutely loved this product!\",\n",
        "    \"This is the worst experience I've ever had.\",\n",
        "    \"\"\n",
        "])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-17T04:07:06.284076Z",
          "iopub.execute_input": "2025-04-17T04:07:06.284607Z",
          "iopub.status.idle": "2025-04-17T04:07:06.296332Z",
          "shell.execute_reply.started": "2025-04-17T04:07:06.284582Z",
          "shell.execute_reply": "2025-04-17T04:07:06.295620Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz3aE_3FQsgw",
        "outputId": "5e161594-4c66-4d21-eea4-ea15dd576788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inference examples\n",
            "'I absolutely loved this product!' -> LABEL_0  (82.02%)\n",
            "'This is the worst experience I've ever had.' -> LABEL_0  (91.46%)\n",
            "'' -> LABEL_1  (39.25%)\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "eFlQr6awQsgw"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}